# AutoTranscription è¯­éŸ³è½¬æ–‡å­—ç³»ç»Ÿ

åŸºäº Faster Whisper çš„é«˜å¹¶å‘å®¢æˆ·ç«¯-æœåŠ¡å™¨æ¶æ„è¯­éŸ³è½¬æ–‡å­—ç³»ç»Ÿï¼Œæ”¯æŒ GPU åŠ é€Ÿå’Œç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ã€‚

## ç‰¹æ€§

- ğŸ¯ **é«˜ç²¾åº¦è¯†åˆ«**: åŸºäº OpenAI Whisper large-v3 æ¨¡å‹
- ğŸš€ **é«˜å¹¶å‘å¤„ç†**: æ”¯æŒ 8-16 ä¸ªåŒæ—¶è½¬å†™è¯·æ±‚ï¼Œ100 ä¸ªè¯·æ±‚é˜Ÿåˆ—
- ğŸ”¥ **GPU åŠ é€Ÿ**: æ”¯æŒ NVIDIA CUDAï¼Œæ˜¾è‘—æå‡è½¬å½•é€Ÿåº¦
- ğŸ­ **ç”Ÿäº§å°±ç»ª**: åŒ…å«è¿›ç¨‹ç®¡ç†ã€å®æ—¶ç›‘æ§ã€å¥åº·æ£€æŸ¥
- ğŸ“Š **æ€§èƒ½ç›‘æ§**: å®æ—¶é˜Ÿåˆ—çŠ¶æ€ã€æˆåŠŸç‡ç»Ÿè®¡ã€è´Ÿè½½ç®¡ç†
- ğŸ”¥ **çƒ­é”®æ”¯æŒ**: å…¨å±€å¿«æ·é”®å¿«é€Ÿå¯åŠ¨å½•éŸ³
- ğŸŒ **ç½‘ç»œæ”¯æŒ**: æ”¯æŒå±€åŸŸç½‘å’Œäº’è”ç½‘è®¿é—®
- ğŸ“ **å®æ—¶è¾“å‡º**: æ”¯æŒæµå¼è½¬å½•ç»“æœ
- ğŸ‡¨ğŸ‡³ **ä¸­æ–‡ä¼˜åŒ–**: é’ˆå¯¹ä¸­æ–‡è¯­éŸ³è¯†åˆ«ä¼˜åŒ–
- ğŸ§  **æ™ºèƒ½å†…å­˜ç®¡ç†**: è‡ªåŠ¨ GPU å†…å­˜æ¸…ç†å’Œä¼˜åŒ–

## å¿«é€Ÿå¼€å§‹

### 1. ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04+, CentOS 7+, å…¶ä»– Linux å‘è¡Œç‰ˆ
- **Python**: 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- **GPU**: NVIDIA GPU (å¯é€‰ï¼Œæ”¯æŒ CPU æ¨¡å¼)
- **CUDA**: 11.8+ (GPU æ¨¡å¼éœ€è¦ï¼Œè‡ªåŠ¨å®‰è£…)
- **å†…å­˜**: å»ºè®® 16GB+ (é«˜å¹¶å‘æ¨¡å¼éœ€è¦æ›´å¤šå†…å­˜)
- **ç½‘ç»œ**: ç¨³å®šçš„ç½‘ç»œè¿æ¥ç”¨äºæ¨¡å‹ä¸‹è½½å’Œ API è°ƒç”¨

### 2. ä¸€é”®å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd autotranscription

# ä¸€é”®å®‰ï¿½ï¿½ï¿½ (è‡ªåŠ¨å®‰è£… Miniconda + CUDA + æ‰€æœ‰ä¾èµ–)
./scripts/manage.sh install
```

> **æ³¨æ„**: å®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶å®‰è£… Miniconda å’Œ CUDA Toolkitï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ã€‚

### 3. å¯åŠ¨ç³»ç»Ÿ

```bash
# å¯åŠ¨å®Œæ•´ç³»ç»Ÿ
./scripts/manage.sh start

# æˆ–è€…åˆ†åˆ«å¯åŠ¨
./scripts/manage.sh server start  # å¯åŠ¨æœåŠ¡ç«¯
./scripts/manage.sh client        # å¯åŠ¨å®¢æˆ·ç«¯
```

### 4. ä½¿ç”¨å®¢æˆ·ç«¯

å¯åŠ¨å®¢æˆ·ç«¯åï¼Œä½¿ç”¨å¿«æ·é”® `Alt` å¼€å§‹å½•éŸ³ï¼Œå†æ¬¡æŒ‰ä¸‹åœæ­¢å½•éŸ³å¹¶è·å–è½¬å½•ç»“æœã€‚

## è¯¦ç»†ä½¿ç”¨

### ç®¡ç†è„šæœ¬ (`./scripts/manage.sh`)

```bash
# ç³»ç»Ÿç®¡ç†
./scripts/manage.sh install       # å®‰è£…ä¾èµ–
./scripts/manage.sh start         # å¯åŠ¨ç³»ç»Ÿ
./scripts/manage.sh stop          # åœæ­¢ç³»ç»Ÿ
./scripts/manage.sh restart       # é‡å¯ç³»ç»Ÿ
./scripts/manage.sh status        # æŸ¥çœ‹çŠ¶æ€

# æœåŠ¡ç«¯ç®¡ç†
./scripts/manage.sh server start     # å¯åŠ¨é«˜å¹¶å‘æœåŠ¡ç«¯
./scripts/manage.sh server stop      # åœæ­¢æœåŠ¡ç«¯
./scripts/manage.sh server status    # æŸ¥çœ‹æœåŠ¡ç«¯çŠ¶æ€
./scripts/manage.sh server logs      # æŸ¥çœ‹æœåŠ¡ç«¯æ—¥å¿—
./scripts/manage.sh server health    # å¥åº·æ£€æŸ¥
./scripts/manage.sh server monitor   # å®æ—¶å¹¶å‘ç›‘æ§

# å®¢æˆ·ç«¯
./scripts/manage.sh client          # å¯åŠ¨å®¢æˆ·ç«¯

# ç³»ç»Ÿç»´æŠ¤
./scripts/manage.sh clean           # æ¸…ç†ç³»ç»Ÿ
./scripts/manage.sh reset           # å®Œå…¨é‡ç½®
```

### æœåŠ¡ç«¯è„šæœ¬ (`./scripts/start_server.sh`)

```bash
./scripts/start_server.sh start     # å¯åŠ¨é«˜å¹¶å‘æœåŠ¡ç«¯
./scripts/start_server.sh stop      # åœæ­¢æœåŠ¡ç«¯
./scripts/start_server.sh restart   # é‡å¯æœåŠ¡ç«¯
./scripts/start_server.sh status    # æŸ¥çœ‹çŠ¶æ€
./scripts/start_server.sh logs      # æŸ¥çœ‹æ—¥å¿—
./scripts/start_server.sh health    # å¥åº·æ£€æŸ¥
./scripts/start_server.sh monitor   # å®æ—¶å¹¶å‘ç›‘æ§
./scripts/start_server.sh config    # æ˜¾ç¤ºé…ç½®
```

### å®¢æˆ·ç«¯è„šæœ¬ (`./scripts/start_client.sh`)

```bash
# åŸºæœ¬ä½¿ç”¨
./scripts/start_client.sh start     # å¯åŠ¨å®¢æˆ·ç«¯
./scripts/start_client.sh check     # æ£€æŸ¥æœåŠ¡è¿æ¥
./scripts/start_client.sh config    # æ˜¾ç¤ºé…ç½®

# ç¯å¢ƒå˜é‡è¦†ç›–
SERVER_URL=http://192.168.1.100:5000 ./scripts/start_client.sh start
HOTKEY="<ctrl>+<alt>+a" ./scripts/start_client.sh start
```

## é…ç½®æ–‡ä»¶

### æœåŠ¡ç«¯é…ç½® (`config/server_config.json`)

```json
{
    "model_size": "large-v3",              // æ¨¡å‹å¤§å°: tiny/base/small/medium/large-v3
    "device": "cuda",                     // è®¾å¤‡: cpu/cuda/auto
    "compute_type": "float16",            // è®¡ç®—ç²¾åº¦: int8/float16/float32
    "network_mode": "lan",                // ç½‘ç»œæ¨¡å¼: lan/internet
    "host": "0.0.0.0",                   // ç›‘å¬åœ°å€
    "port": 5000,                        // ç›‘å¬ç«¯å£
    "workers": 8,                        // Gunicorn å·¥ä½œè¿›ç¨‹æ•°
    "max_concurrent_transcriptions": 16,  // æœ€å¤§å¹¶å‘è½¬å†™æ•°
    "queue_size": 100,                   // è¯·æ±‚é˜Ÿåˆ—å¤§å°
    "timeout": 600,                      // è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
    "log_level": "INFO"                  // æ—¥å¿—çº§åˆ«
}
```

**é«˜å¹¶å‘é…ç½®è¯´æ˜**:
- `max_concurrent_transcriptions`: åŒæ—¶å¤„ç†çš„æœ€å¤§è½¬å†™è¯·æ±‚æ•°
- `queue_size`: è¯·æ±‚é˜Ÿåˆ—å®¹é‡ï¼Œæ»¡è½½æ—¶è¿”å› 503 é”™è¯¯
- `workers`: Gunicorn å·¥ä½œè¿›ç¨‹æ•°ï¼Œå»ºè®® CPU æ ¸å¿ƒæ•° Ã— 2

### å®¢æˆ·ç«¯é…ç½® (`config/client_config.json`)

```json
{
    "server_url": "http://localhost:5000",  // æœåŠ¡ç«¯åœ°å€
    "max_time": 30,                         // æœ€å¤§å½•éŸ³æ—¶é•¿(ç§’)
    "zh_convert": "none",                   // ä¸­æ–‡è½¬æ¢: none/t2s/s2t
    "streaming": true,                      // æµå¼è¾“å‡º
    "key_combo": "<alt>",                   // å¿«æ·é”®ç»„åˆ
    "sample_rate": 16000,                   // é‡‡æ ·ç‡
    "channels": 1                           // å£°é“æ•°
}
```

## API æ¥å£

æœåŠ¡ç«¯æä¾› RESTful APIï¼š

### å¥åº·æ£€æŸ¥
```http
GET /api/health
```

### è·å–é…ç½®
```http
GET /api/config
```

### è·å–è¯¦ç»†çŠ¶æ€
```http
GET /api/status
```

è¿”å›å®æ—¶æ€§èƒ½æŒ‡æ ‡ï¼š
- é˜Ÿåˆ—å¤§å°å’Œä½¿ç”¨ç‡
- æ´»è·ƒè½¬å†™æ•°é‡
- æˆåŠŸ/å¤±è´¥è¯·æ±‚ç»Ÿè®¡
- æ¨¡å‹ä¿¡æ¯

### è¯­éŸ³è½¬å½• (JSONæ ¼å¼)
```http
POST /api/transcribe
Content-Type: application/json

{
    "audio_data": [éŸ³é¢‘æ•°æ®æ•°ç»„],
    "sample_rate": 16000,
    "language": "zh",
    "initial_prompt": "ä»¥ä¸‹æ˜¯æ™®é€šè¯å¥å­ã€‚",
    "streaming": false
}
```

### è¯­éŸ³è½¬å½• (äºŒè¿›åˆ¶æ ¼å¼)
```http
POST /api/transcribe_binary
Content-Type: application/octet-stream
X-Sample-Rate: 16000
X-Language: zh
X-Initial-Prompt: ä»¥ä¸‹æ˜¯æ™®é€šè¯å¥å­ã€‚

[äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®]
```

## ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### 1. ç³»ç»ŸæœåŠ¡é…ç½®

åˆ›å»º systemd æœåŠ¡æ–‡ä»¶ï¼š

```bash
sudo nano /etc/systemd/system/autotranscription.service
```

```ini
[Unit]
Description=AutoTranscription Service
After=network.target

[Service]
Type=forking
User=your-username
WorkingDirectory=/path/to/autotranscription
ExecStart=/path/to/autotranscription/scripts/start_server.sh start
ExecStop=/path/to/autotranscription/scripts/start_server.sh stop
ExecReload=/path/to/autotranscription/scripts/start_server.sh restart
PIDFile=/path/to/autotranscription/logs/transcription_server.pid
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

å¯ç”¨å’Œå¯åŠ¨æœåŠ¡ï¼š

```bash
sudo systemctl daemon-reload
sudo systemctl enable autotranscription
sudo systemctl start autotranscription
sudo systemctl status autotranscription
```

### 2. åå‘ä»£ç†é…ç½® (Nginx)

```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://127.0.0.1:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
    }
}
```

### 3. é˜²ç«å¢™é…ç½®

```bash
# Ubuntu/Debian
sudo ufw allow 5000/tcp

# CentOS/RHEL
sudo firewall-cmd --permanent --add-port=5000/tcp
sudo firewall-cmd --reload
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹ä¸‹è½½å¤±è´¥**
   ```bash
   # æ£€æŸ¥ç½‘ç»œè¿æ¥
   curl -I https://huggingface.co

   # é‡æ–°å®‰è£…ä¾èµ–
   ./scripts/manage.sh clean
   ./scripts/manage.sh install
   ```

2. **GPU ä¸å¯ç”¨**
   ```bash
   # æ£€æŸ¥ NVIDIA é©±åŠ¨
   nvidia-smi

   # æ£€æŸ¥ CUDA å®‰è£…
   nvcc --version

   # å¼ºåˆ¶ä½¿ç”¨ CPU æ¨¡å¼
   # ç¼–è¾‘ config/server_config.jsonï¼Œè®¾ç½® "device": "cpu"
   ```

3. **ç«¯å£è¢«å ç”¨**
   ```bash
   # æŸ¥çœ‹ç«¯å£å ç”¨
   sudo netstat -tlnp | grep :5000

   # æ›´æ”¹ç«¯å£
   # ç¼–è¾‘ config/server_config.jsonï¼Œä¿®æ”¹ "port" å€¼
   ```

4. **æƒé™é—®é¢˜**
   ```bash
   # ç¡®ä¿è„šæœ¬æœ‰æ‰§è¡Œæƒé™
   chmod +x scripts/*.sh

   # æ£€æŸ¥æ—¥å¿—ç›®å½•æƒé™
   sudo chown -R $USER:$USER logs/
   ```

### æ—¥å¿—æ–‡ä»¶ä½ç½®

- æœåŠ¡ç«¯æ—¥å¿—: `logs/transcription_server.log`
- é”™è¯¯æ—¥å¿—: `logs/transcription_server_error.log`
- å®¢æˆ·ç«¯æ—¥å¿—: `logs/client.log`

### æ€§èƒ½ä¼˜åŒ–å’Œç›‘æ§

1. **å®æ—¶ç›‘æ§**
   ```bash
   # å®æ—¶å¹¶å‘ç›‘æ§ä»ªè¡¨æ¿
   ./scripts/manage.sh server monitor

   # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
   curl http://localhost:5000/api/status

   # å¥åº·æ£€æŸ¥
   curl http://localhost:5000/api/health
   ```

2. **GPU ä¼˜åŒ–**
   - ä½¿ç”¨ `compute_type: "float16"` æå‡é€Ÿåº¦
   - ç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU æ˜¾å­˜ (å»ºè®® 8GB+)
   - ç³»ç»Ÿä¼šè‡ªåŠ¨æ¸…ç† GPU å†…å­˜

3. **å¹¶å‘ä¼˜åŒ–**
   - è°ƒæ•´ `max_concurrent_transcriptions` åŸºäº GPU å†…å­˜ (8-16)
   - è°ƒæ•´ `workers` å‚æ•° (å»ºè®® CPU æ ¸å¿ƒæ•° Ã— 2)
   - å¢åŠ  `queue_size` å¤„ç†çªå‘è¯·æ±‚

4. **ç½‘ç»œä¼˜åŒ–**
   - ä½¿ç”¨äºŒè¿›åˆ¶ API (`/api/transcribe_binary`) å‡å°‘ä¼ è¾“å¼€é”€
   - é…ç½®åˆé€‚çš„è¶…æ—¶æ—¶é—´ (é»˜è®¤ 600 ç§’)

### æ€§èƒ½æŒ‡æ ‡

**é¢„æœŸæ€§èƒ½**:
- **å¹¶å‘èƒ½åŠ›**: 8-16 ä¸ªåŒæ—¶è½¬å†™è¯·æ±‚
- **é˜Ÿåˆ—å®¹é‡**: 100 ä¸ªè¯·æ±‚æ’é˜Ÿ
- **ååé‡**: 800-2000 è½¬å†™/å°æ—¶ (å–å†³äºéŸ³é¢‘é•¿åº¦)
- **å“åº”æ—¶é—´**: 10-60 ç§’ (å–å†³äºéŸ³é¢‘é•¿åº¦å’Œæ¨¡å‹)

**ç›‘æ§æŒ‡æ ‡**:
- é˜Ÿåˆ—ä½¿ç”¨ç‡ (å»ºè®® < 80%)
- å¹¶å‘ä½¿ç”¨ç‡ (å»ºè®® < 90%)
- æˆåŠŸç‡ (åº”è¯¥ > 95%)
- å¹³å‡å“åº”æ—¶é—´

## å¼€å‘è¯´æ˜

### é¡¹ç›®ç»“æ„

```
autotranscription/
â”œâ”€â”€ client/                 # å®¢æˆ·ç«¯ä»£ç 
â”‚   â”œâ”€â”€ client.py          # ä¸»å®¢æˆ·ç«¯ç¨‹åº (çŠ¶æ€æœº + çƒ­é”®æ”¯æŒ)
â”‚   â””â”€â”€ requirements.txt   # å®¢æˆ·ç«¯ä¾èµ–
â”œâ”€â”€ server/                # æœåŠ¡ç«¯ä»£ç 
â”‚   â”œâ”€â”€ transcription_server.py  # é«˜å¹¶å‘è½¬å†™æœåŠ¡å™¨
â”‚   â””â”€â”€ requirements.txt   # æœåŠ¡ç«¯ä¾èµ–
â”œâ”€â”€ config/                # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ server_config.json # æœåŠ¡ç«¯é…ç½® (å«å¹¶å‘è®¾ç½®)
â”‚   â””â”€â”€ client_config.json # å®¢æˆ·ç«¯é…ç½®
â”œâ”€â”€ scripts/               # ç®¡ç†è„šæœ¬
â”‚   â”œâ”€â”€ install_deps.sh    # è‡ªåŠ¨å®‰è£… (Miniconda + CUDA)
â”‚   â”œâ”€â”€ start_server.sh    # æœåŠ¡ç«¯ç®¡ç† (å«ç›‘æ§)
â”‚   â”œâ”€â”€ start_client.sh    # å®¢æˆ·ç«¯å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ manage.sh          # ç»¼åˆç®¡ç†è„šæœ¬
â”‚   â”œâ”€â”€ verify_cleanup.sh  # ç¯å¢ƒéªŒè¯å·¥å…·
â”‚   â””â”€â”€ cuda_check.sh      # CUDA ç¯å¢ƒè¯Šæ–­
â”œâ”€â”€ logs/                  # æ—¥å¿—ç›®å½•
â”œâ”€â”€ systemd/               # ç³»ç»ŸæœåŠ¡é…ç½®
â””â”€â”€ CLAUDE.md              # Claude Code å¼€å‘æŒ‡å—
```

### æ¶æ„ç‰¹ç‚¹

**é«˜å¹¶å‘æœåŠ¡ç«¯**:
- ThreadPoolExecutor ç®¡ç†å¹¶å‘è½¬å†™ (8-16 ä¸ªåŒæ—¶)
- è¯·æ±‚é˜Ÿåˆ—ç³»ç»Ÿ (100 ä¸ªå®¹é‡)
- è‡ªåŠ¨ GPU å†…å­˜ç®¡ç†
- å®æ—¶æ€§èƒ½ç›‘æ§ API

**å®¢æˆ·ç«¯**:
- çŠ¶æ€æœºæ¶æ„ (READY â†’ RECORDING â†’ TRANSCRIBING â†’ REPLAYING)
- å…¨å±€çƒ­é”®æ”¯æŒ (pynput)
- è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†
- ä¸­æ–‡æ–‡æœ¬è½¬æ¢æ”¯æŒ

### å¼€å‘å’Œè°ƒè¯•

1. **ç¯å¢ƒéªŒè¯**
   ```bash
   ./scripts/verify_cleanup.sh     # éªŒè¯ç¯å¢ƒå®Œæ•´æ€§
   ./scripts/cuda_check.sh         # æ£€æŸ¥ CUDA ç¯å¢ƒ
   ```

2. **å¼€å‘è°ƒè¯•**
   ```bash
   # å¼€å‘æ¨¡å¼å¯åŠ¨æœåŠ¡ç«¯ (å‰å°è¿è¡Œ)
   cd server && python transcription_server.py

   # æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
   ./scripts/manage.sh server logs

   # æµ‹è¯• API è¿æ¥
   ./scripts/start_client.sh check
   ```

3. **æ·»åŠ æ–°åŠŸèƒ½**
   1. ä¿®æ”¹ç›¸åº”çš„é…ç½®æ–‡ä»¶
   2. æ›´æ–°æœåŠ¡ç«¯/å®¢æˆ·ç«¯ä»£ç 
   3. ä½¿ç”¨ `./scripts/manage.sh restart` é‡å¯æœåŠ¡æµ‹è¯•
   4. é€šè¿‡ç›‘æ§åŠŸèƒ½éªŒè¯æ€§èƒ½å½±å“

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚

## æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issue æˆ– Pull Requestã€‚